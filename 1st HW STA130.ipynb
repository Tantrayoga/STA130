{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf9e012",
   "metadata": {},
   "source": [
    "# PreLecture HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f22b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9934a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
       "        'song', 'phrase', 'full_id', 'url'],\n",
       "       dtype='object'),\n",
       " 391)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided link\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# Get the columns of the dataset and the number of rows (data points)\n",
    "columns = villagers_df.columns\n",
    "num_rows = villagers_df.shape[0]\n",
    "\n",
    "columns, num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955b934",
   "metadata": {},
   "source": [
    "# 2.2 Instruciton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on my summary of the explanation from chatGPT, the observation term means the individual villager (each of \n",
    "the villager).For the variables, they give the identity and characteristics that the villager have like name, \n",
    "gender, species, birthday, etc.Therfore, in my opinion, this dataset is giving data about villagers and \n",
    "information for their identity and characteristics.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a408ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics for Numeric Columns:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "Preview of First 5 Rows:\n",
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "Unique values and their counts\n",
      "Column: row_n\n",
      "row_n\n",
      "2      1\n",
      "303    1\n",
      "331    1\n",
      "330    1\n",
      "328    1\n",
      "      ..\n",
      "151    1\n",
      "150    1\n",
      "149    1\n",
      "148    1\n",
      "483    1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "\n",
      "Column: id\n",
      "id\n",
      "admiral    1\n",
      "mott       1\n",
      "paula      1\n",
      "patty      1\n",
      "pate       1\n",
      "          ..\n",
      "eloise     1\n",
      "elmer      1\n",
      "ellie      1\n",
      "elise      1\n",
      "zucker     1\n",
      "Name: count, Length: 390, dtype: int64\n",
      "\n",
      "\n",
      "Column: name\n",
      "name\n",
      "Admiral    1\n",
      "Muffy      1\n",
      "Paula      1\n",
      "Patty      1\n",
      "Pate       1\n",
      "          ..\n",
      "Elvis      1\n",
      "Eloise     1\n",
      "Elmer      1\n",
      "Ellie      1\n",
      "Zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "\n",
      "Column: gender\n",
      "gender\n",
      "male      204\n",
      "female    187\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column: species\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column: birthday\n",
      "birthday\n",
      "1-27     2\n",
      "12-5     2\n",
      "7-31     2\n",
      "3-26     2\n",
      "8-3      2\n",
      "        ..\n",
      "4-3      1\n",
      "10-26    1\n",
      "7-23     1\n",
      "12-8     1\n",
      "3-8      1\n",
      "Name: count, Length: 361, dtype: int64\n",
      "\n",
      "\n",
      "Column: personality\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Column: song\n",
      "song\n",
      "K.K. Country     10\n",
      "Forest Life       9\n",
      "Imperial K.K.     7\n",
      "K.K. Soul         7\n",
      "K.K. Ragtime      7\n",
      "                 ..\n",
      "Aloha K.K.        2\n",
      "Drivin'           1\n",
      "Senor K.K.        1\n",
      "K.K.  Bazaar      1\n",
      "K.K. D&B          1\n",
      "Name: count, Length: 92, dtype: int64\n",
      "\n",
      "\n",
      "Column: phrase\n",
      "phrase\n",
      "wee one       2\n",
      "quacko        2\n",
      "bloop         2\n",
      "aye aye       1\n",
      "snoot         1\n",
      "             ..\n",
      "lambchop      1\n",
      "yeah buddy    1\n",
      "chow down     1\n",
      "unh-hunh      1\n",
      "pronk         1\n",
      "Name: count, Length: 388, dtype: int64\n",
      "\n",
      "\n",
      "Column: full_id\n",
      "full_id\n",
      "villager-admiral    1\n",
      "villager-muffy      1\n",
      "villager-paula      1\n",
      "villager-patty      1\n",
      "villager-pate       1\n",
      "                   ..\n",
      "villager-elvis      1\n",
      "villager-eloise     1\n",
      "villager-elmer      1\n",
      "villager-ellie      1\n",
      "villager-zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "\n",
      "Column: url\n",
      "url\n",
      "https://villagerdb.com/images/villagers/thumb/admiral.98206ee.png    1\n",
      "https://villagerdb.com/images/villagers/thumb/muffy.1497c92.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/paula.563ba81.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/patty.3e17f7f.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/pate.c60838c.png       1\n",
      "                                                                    ..\n",
      "https://villagerdb.com/images/villagers/thumb/elvis.57d4757.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/eloise.112208b.png     1\n",
      "https://villagerdb.com/images/villagers/thumb/elmer.cc7df52.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/ellie.5a144a6.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/zucker.8dbb719.png     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Result of df.shape\n",
      "(391, 11)\n"
     ]
    }
   ],
   "source": [
    "# Simple summary of the dataset\n",
    "def simple_summary(df):\n",
    "    print(\"Dataset Information:\")\n",
    "    print(df.info())  # Basic info about data types and non-null values\n",
    "    \n",
    "    print(\"\\nSummary Statistics for Numeric Columns:\")\n",
    "    print(df.describe())  # Summary statistics for numerical columns\n",
    "    \n",
    "    print(\"\\nPreview of First 5 Rows:\")\n",
    "    print(df.head())  # Preview the first 5 rows\n",
    "    \n",
    "    print(\"\\nUnique values and their counts\")\n",
    "    # Loop through each column and print unique values and their counts\n",
    "    for column in villagers_df.columns:\n",
    "        print(f\"Column: {column}\")\n",
    "        print(villagers_df[column].value_counts())\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    print(\"\\nResult of df.shape\")\n",
    "    print(df.shape)\n",
    "\n",
    "# Use the function for the villagers dataset\n",
    "simple_summary(villagers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc1934",
   "metadata": {},
   "source": [
    "# Before Instruction 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9390c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I am going to change my dataset to https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "It's because the village.csv only has one numeric variable\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1612372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "Number of rows in the dataset: 891\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the new URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Get the columns of the dataset and the number of rows (data points)\n",
    "columns = titanic_df.columns\n",
    "num_rows = titanic_df.shape[0]\n",
    "\n",
    "print(\"Columns in the dataset:\", columns)\n",
    "print(\"Number of rows in the dataset:\", num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61d9c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics for Numeric Columns:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "\n",
      "Preview of First 5 Rows:\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "Result of df.shape\n",
      "(891, 15)\n"
     ]
    }
   ],
   "source": [
    "# Simple summary of the Titanic dataset\n",
    "def simple_summary(df):\n",
    "    print(\"Dataset Information:\")\n",
    "    print(df.info())  # Basic info about data types and non-null values\n",
    "    \n",
    "    print(\"\\nSummary Statistics for Numeric Columns:\")\n",
    "    print(df.describe())  # Summary statistics for numerical columns\n",
    "    \n",
    "    print(\"\\nPreview of First 5 Rows:\")\n",
    "    print(df.head())  # Preview the first 5 rows\n",
    "    \n",
    "    print(\"\\nResult of df.shape\")\n",
    "    print(df.shape)\n",
    "\n",
    "# Use the function for the Titanic dataset\n",
    "simple_summary(titanic_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31ba0b",
   "metadata": {},
   "source": [
    "# Instruction 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c730ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The df.shape only gives us the dimension of the DataFrame which is rows and columns. In this case, \n",
    "It's showing that the data set has 891 rows and 15 columns from the df.shape method. \n",
    "However, for df.describe(). It provides the numeric columns by default. This function give statistics like mean,\n",
    "stantard deviation, minimum, maximum, and values. \n",
    "\n",
    "The reason why there is disrepencies between df.shape and df.describe is non numeric columns will not be included\n",
    "in the output unless you specify (include all). Furthermore, df.describe() only shows the number of non missing \n",
    "values for each numeric columns. In this case, the missing values are not counted where it makes there are differences\n",
    "between df.describe() and df.shape (which only calculate the rows and columns in DataFrame)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ad0ba",
   "metadata": {},
   "source": [
    "# Instruction 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Attribute which doesn't use \"()\" like df.shape is used for stores and retrieves information about an object.\n",
    "Because it's not function, it's return information that is already stored.\n",
    "\n",
    "On the other hand, method which use \"()\" like df.describe() is function that object can perform in python.\n",
    "It performs an action or computation on an object(which is the data).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be686c3",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee56ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here's a summary of our current chat session:\n",
    "\n",
    "Dataset Switch: You switched from working on the \"villagers.csv\" dataset to the \"Titanic\" dataset from the URL: \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv.\"\n",
    "\n",
    "Initial Analysis: I provided Python code to:\n",
    "\n",
    "Load the Titanic dataset.\n",
    "Display its columns and row count.\n",
    "Simple Summary: I guided you to create a basic summary of the Titanic dataset using the info(), describe(), and head() methods to understand its structure, statistics, and preview the first 5 rows.\n",
    "\n",
    "Attributes vs Methods Explanation: I explained the difference between an attribute (e.g., df.shape) and a method (e.g., df.describe()), focusing on how attributes retrieve stored information while methods perform actions or computations.\n",
    "\n",
    "This summary highlights key topics and codes discussed during this session!\n",
    "\"\"\"\n",
    "\n",
    "#Chat log histories:\n",
    "#https://chatgpt.com/share/41b1b4d2-82d7-43d0-a198-03d4ba307a50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf74cb5",
   "metadata": {},
   "source": [
    "# PostLecture HW "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50649564",
   "metadata": {},
   "source": [
    "# Instruction 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are 8 variables that given by the summary from df.describe() method, which are:\n",
    "\n",
    "1. Count: It's the number counted of non-null (non-missing) values for each non numeric columns as I said before in instruction 4. It tells you how many valid observations there are.\n",
    "2. Mean: The same as in math. It's the average value of the data, calculated by summing all values and dividing by the number of observations (count).\n",
    "3. Standard Deviation (std): It's also used in mathematics that has a purpose to measure the amount of variation or dispersion of a set of values. It shows how much individual data points typically deviate from the mean. A higher standard deviation means more spread out data.\n",
    "4. Minimum (min): The smallest value in the data for each variable or column.\n",
    "5. 25% (First Quartile): The value below which 25% of the data falls. This is also known as the first quartile (Q1).\n",
    "6. 50% (Median or Second Quartile): The middle value of the data. This is the point at which half of the data values are less and half are greater. This is also referred to as the second quartile (Q2) or the median.\n",
    "7. 75% (Third Quartile): The value below which 75% of the data falls. This is also known as the third quartile (Q3).\n",
    "8. Maximum (max): The largest value in the data for each variable.\n",
    "\n",
    "Those things are actually being studied in mathematics/statistics in high school(IB, AP, A level) or college.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce9a13",
   "metadata": {},
   "source": [
    "# Instruction 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are 4 instructions:\n",
    "\n",
    "1)Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col'] df.dropna() is preferred when you want to remove rows (or columns) that contain missing values, but still want to preserve other columns. \n",
    "- df.dropna() is preferred when you want to remove rows (or columns) that contain missing values, but still want to preserve other columns. \n",
    "- In this case, you have a dataset with missing values in various rows and want to remove all rows with any missing data. For my dataset: Imagine you are analyzing passengers from the Titanic dataset and want to remove rows where any column (like age, fare, etc.) has missing values.\n",
    "\n",
    "2)Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()\n",
    "- del df['col'] is preferred when you want to delete an entire column, regardless of whether it has missing values or not. For example, You have a dataset with a column that isn't useful for your analysis, such as an ID column, and you want to remove it. For my dataset the example is: Imagine you are analyzing the Titanic dataset but donâ€™t need the \"Cabin\" column because it's not relevant to your analysis, so you delete it.\n",
    "\n",
    "3)Discuss why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "- The reason is if you delete columns that are unnecessary before using df.dropna(), you avoid accidentally dropping rows due to missing values in those columns.\n",
    "- In this case, deleting irrelevant columns first reduces the risk of unnecessarily discarding rows with valuable information in the columns that matter.\n",
    "- Example: If you want to drop rows with missing values, but there's a column like \"Cabin\" with many missing values that you don't need for analysis, using del df['Cabin'] first would prevent losing many rows due to missing \"Cabin\" values when you run df.dropna() later.\n",
    "\n",
    "4)Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.\n",
    "- I did it in python and the code is below. \n",
    "\n",
    "- Justification:\n",
    "    1. I removed the \"Cabin\" column using del because it has many missing values and is not important for the analysis.\n",
    "    2. I then used df.dropna() to remove rows with missing data in the remaining columns, ensuring that our final dataset has complete information.\n",
    "\n",
    "- Before and After Report:\n",
    "    1. Before cleaning, we will see the number of missing values in various columns like \"Age\" and \"Embarked.\"\n",
    "    2. After cleaning, there should be no missing values, and the dataset will be reduced in size, keeping only rows with complete data.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f422728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data before cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Column 'Deck' Deleted\n",
      "\n",
      "Missing data after cleaning:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n",
      "\n",
      "Cleaned dataset:\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male  embark_town alive  alone  \n",
      "0    man        True  Southampton    no  False  \n",
      "1  woman       False    Cherbourg   yes  False  \n",
      "2  woman       False  Southampton   yes   True  \n",
      "3  woman       False  Southampton   yes  False  \n",
      "4    man        True  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "# Display initial information about missing data\n",
    "print(\"Missing data before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop a column with a significant amount of missing values (e.g., 'deck')\n",
    "print(\"\\nColumn 'Deck' Deleted\")\n",
    "del df['deck']\n",
    "\n",
    "# Remove rows with any remaining missing data\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display cleaned dataset information\n",
    "print(\"\\nMissing data after cleaning:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Print the first few rows of the cleaned dataset\n",
    "print(\"\\nCleaned dataset:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e52c6a",
   "metadata": {},
   "source": [
    "# Instruction 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c90bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are 3 task:\n",
    "1) Use your ChatBot session to understand what df.groupby(\"col1\")[\"col2\"].describe() does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf82be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m grouped_stats \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43malive\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(grouped_stats)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alive' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "\n",
    "grouped_stats = df.groupby(alive)[\"age\"].describe()\n",
    "print(grouped_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For this task, I used the template on chatGPT but changed the data from 'gender' to 'alive'. \n",
    "df.groupby(\"col1\")[\"col2\"].describe() is used if we are going to find the summary statistic with the values of col2 within each group of col2.\n",
    "\n",
    "In the code above, it provides statistic about the value of col2 which is 'age' distributed across different groups in col1 which is 'alive'. In this case, it shows statistic like mean, min, max, quartils about the age of people who come back alive and not. I use age as it's has numeric values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfdae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From my chat gpt log, I can explain that:\n",
    "df.describe() looks at each column independently. It gives summary statistics and counting non-missing data for each column in isolation. The count is different for each column based on the amount of missing data in that specific column.\n",
    "\n",
    "df.groupby(\"col1\")[\"col2\"].describe() groups the data by col1 and provides summary statistics for col2 within each group. The count in this case captures how many non-missing values of col2 are available within each group of col1, showing the distribution of missingness and data completeness across the grouping categories.\n",
    "\n",
    "In df.describe(), the count for each column reflects the total number of non-missing values for that column across the entire dataset. In contrast, df.groupby(\"col1\")[\"col2\"].describe() gives the count of non-missing \"col2\" values within each group of \"col1\", providing insights into how missingness or data availability varies within specific subgroups rather than across the whole dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765719bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d54873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A. Forget to include import pandas as pd in your code\n",
    "I tried it and the output is complex but the main output is: The\"NameError: name 'pd' is not defined\" \n",
    "\n",
    "#I tried to search in Google the first outcome is answer in overflow platform. I opened it but it did answer the \n",
    "question but it's really complex, and i have to find the answer with most likes. Then, I go back, and I find people\n",
    "also asks collumn and said that you have to inlcude import pandas as pd which is the answer i want\n",
    "\n",
    "#For ChatGPT, the answer is precise and fast. It's directly answer my question which is I have to include import \n",
    "pandas.\n",
    "\n",
    "Conclusion for A: I think ChatGPT is easier and simpler.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797110fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "B. Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "\n",
    "I tried with titans.csv and the output is: FileNotFoundError: [Errno 2] No such file or directory: 'titans.csv'\n",
    "\n",
    "#By googling this time, I got the answer pretty fast and precise. The answer is \"The above error shows that you \n",
    "did not place the csv file in the same directory where the code file has been placed\" which means that I didn't place\n",
    "the csv file in the same directory or it also means that I direct it mistakenly. \n",
    "\n",
    "#For ChatGPT, the answer is pretty the same with before. It's fast, precise, and details. It give reccomendation and\n",
    "even give me the Python code I should put. \n",
    "\n",
    "Conclusion For B: Google is really good and efficient at this time. However, ChatGPT give recomendations that \n",
    "really useful and make it easier. We can also asks for explanation if we don't understand about the method in the function.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eee5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "C. Try to use a dataframe before it's been assigned into the variable\n",
    "\n",
    "I tried by changing the df.groupby(\"col1\")[\"col2\"].describe() to be dF.groupby(\"col1\")[\"col2\"].describe(), then \n",
    "The result is: \"NameError: name 'dF' is not defined\"\n",
    "\n",
    "#Same as the B one, Google can give quick answer for this question. It's said\"To avoid the NameError , \n",
    "you need to make sure that your DataFrame df is declared before it's accessed\"\n",
    "\n",
    "#For ChatGPT, the answer is clear, it said that I have a typo which is I should use df not dF. Furthermore it gave\n",
    "the correct code.\n",
    "\n",
    "Conclusion For C: Google is giving the right answer. However, ChatGPT give all explanations that are\n",
    "really useful and make me understand. It also gave us the correct codes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c536dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "D. Forget one of the parentheses somewhere the code\n",
    "\n",
    "I tried with forget the first parenthese: df = pd.read_csv'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "The result is: SyntaxError: unmatched ')'\n",
    "\n",
    "#Google doesn't has a really good answer this time, I have to scroll down and look for website like reddit and etc.\n",
    "In this case, it's not giving precise answer like before.\n",
    "\n",
    "#For ChatGPT, the answer is still realy nice. It said that: The SyntaxError: unmatched ')' occurs when \n",
    "there is an extra or missing closing parenthesis in your code. In this case, it's giving the correct answer for the\n",
    "error that I have.\n",
    "\n",
    "Conclusion For D: Compared to Google, also this time, Chat GPT has much better answer. It gave explanations and also the\n",
    "correct code. On the other hand, Google isn't that good, I need to find the answer from websites given after googling.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "E. Mistype one of the names of the chained functions with the code\n",
    "I tried it by changing describe to besribe: grouped_stats = df.groupby(\"alive\")[\"age\"].bescribe()\n",
    "The result is: \"AttributeError: 'SeriesGroupBy' object has no attribute 'bescribe'\"\n",
    "\n",
    "#I got a good answer from google which pretty fast and precise for this error. The answer is \"Ensure that the attribute name \n",
    "is spelled correctly.\n",
    "\n",
    "#Same as before for chatGPT. It's fast, precise, and details. It give answer: Ensure you're using the correct method name: describe() (not bescribe). \n",
    ". It gave reccomendation and even gave me the Python code I should have put. \n",
    "\n",
    "Conclusion For E: Google is excellent and efficient at this time. However, ChatGPT give the best answer with\n",
    "explanations, recomendations, and codes that really useful and make it easier. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390baac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "F. Use a column name that's not in your data for the groupby and column selection\n",
    "\n",
    "I tried by changing 'alive' to 'Alive', the errors shown after I run it is really long but overall it says\n",
    "\"KeyError: 'Alive'\"\n",
    "\n",
    "#By googling, I found a lot of good answers. Although it's not details, it's stated that I called the false key or\n",
    "key that's not exist for the code\n",
    "\n",
    "#In ChatGPT, it's fast, precise, and details. It said \"The KeyError: 'Alive' means that the column 'Alive' does \n",
    "not exist in your DataFrame.\" Same as before, it also gave the correct answer for this question.\n",
    "\n",
    "Conclusion For F: Google is pretty good, quick, and precise. However, ChatGPT still win as it give the explanation and\n",
    "the right code that really useful and make it easier.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30869e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "G. Forget to put the column name as a string in quotes for the groupby and column selection, \n",
    "and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "\n",
    "I tried with by using: grouped_stats = df.groupby(alive)[\"age\"].describe()\n",
    "Error given: NameError: name 'alive' is not defined\n",
    "\n",
    "#Google didn't give the exact answer for it. It only says that the problem is that I don't have the variable named\n",
    "alive. Even if I try to put my code on it, it's going to useless except I put it in reddit or github. It gave answer\n",
    "but not the exact one.\n",
    "\n",
    "#For ChatGPT, \n",
    "The answer is same as always. It gave precise, exact, and details answers with explanation and the correct answer\n",
    "It said that \"The error NameError: name 'alive' is not defined occurs because 'alive' is being used without quotes. \n",
    "If you're trying to reference a column name, it must be enclosed in quotes to be recognized as a string.\"\n",
    "\n",
    "Conclusion For G: Googling is pretty bad this time, although it still gave answer. This time, ChatGPT really helpful\n",
    "compared to googling. As google didn't give answer, ChatGPT did with explanation, reccomendation, and the correct code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cea45b",
   "metadata": {},
   "source": [
    "# Instruction 9\n",
    "Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?\n",
    "\n",
    "Yes, already reviewed the course wiki-textbook. I did it, but have not reviewed everything yet.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd17ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary for Post Lecture HW from ChatGPT\n",
    "\n",
    "\n",
    "1. **Summary Statistics Definitions**: Provided definitions for `df.describe()` summary statistics including count, mean, std, min, 25%, 50%, 75%, and max.\n",
    "\n",
    "2. **Data Cleaning**:\n",
    "   - Provided code to remove missing data using `del df['col']` and `df.dropna()`.\n",
    "   - Demonstrated how to clean the Titanic dataset by removing a column with many missing values and dropping rows with any missing data.\n",
    "\n",
    "3. **Code Explanation**:\n",
    "   - Explained what `df.groupby(\"col1\")[\"col2\"].describe()` does, including grouping by a column and describing statistics for another column within each group.\n",
    "   - Clarified the difference between `df.describe()` and `df.groupby(\"col1\")[\"col2\"].describe()` in terms of how they handle missing values and provide counts.\n",
    "\n",
    "4. **Errors and Troubleshooting**:\n",
    "   - **NameError**: Resolved the issue related to `pd` not being defined by suggesting to ensure `import pandas as pd`.\n",
    "   - **FileNotFoundError**: Advised on checking file paths and names, and provided a correct URL for the Titanic dataset.\n",
    "   - **SyntaxError**: Addressed unmatched parentheses and provided guidance on checking and correcting parentheses in code.\n",
    "   - **AttributeError**: Corrected the typo `bescribe` to `describe`.\n",
    "   - **KeyError**: Suggested verifying column names and corrected usage of column names.\n",
    "   - **NameError for 'alive'**: Explained that it could be due to a typo or incorrect reference and provided steps to resolve it.\n",
    "\n",
    "Feel free to ask if you need more details or further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e4179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chat Log History Chat GPT for PreLecture HW\n",
    "#https://chatgpt.com/share/41b1b4d2-82d7-43d0-a198-03d4ba307a50\n",
    "\n",
    "#Chat Log History Chat GPT for PostLecture HW\n",
    "#https://chatgpt.com/share/66e36698-c9a4-8002-b452-fc1dc37b3dc2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
